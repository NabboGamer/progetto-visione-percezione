{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ce0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.insert(19, 'litepose-pose-estimation/src')\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import lp_config.lp_common_config as cc\n",
    "from lp_model.lp_litepose import LitePose\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, drawSkeleton\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "sys.path.insert(20, 'src/referee_gloves_detector')\n",
    "from color_labeler import ColorLabeler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggo il file di configurazione\n",
    "with open('config/config.json') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "# Ottengo i percorsi dei file\n",
    "file_path_big_arch = config_data['path_big_arch']\n",
    "file_path_csv_keypoints_webcam = config_data['path_csv_keypoints_webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(file_path_big_arch, map_location=cc.config[\"device\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65804b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Filtering\n",
    "\n",
    "image = cv2.imread('src/referee_gloves_detector/bloisi_nao_red_hands.png')\n",
    "# image = cv2.imread('src/referee_gloves_detector/person_with_red_boxing_gloves.png')\n",
    "cv2.imshow(\"Original\", image)\n",
    " \n",
    "result = image.copy()\n",
    " \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "lower1 = np.array([0, 100, 100])\n",
    "upper1 = np.array([5, 255, 255])\n",
    "\n",
    "lower2 = np.array([174,100,100])\n",
    "upper2 = np.array([179,255,255])\n",
    " \n",
    "lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "upper_mask = cv2.inRange(image, lower2, upper2)\n",
    " \n",
    "full_mask = lower_mask + upper_mask;\n",
    " \n",
    "result = cv2.bitwise_and(result, result, mask=full_mask)\n",
    "\n",
    "cv2.imshow('mask', full_mask)\n",
    "cv2.imshow('result', result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red Filtering + Cropping\n",
    "\n",
    "# image = cv2.imread('src/referee_gloves_detector/bloisi_nao_red_hands.png')\n",
    "# image = cv2.imread('src/referee_gloves_detector/person_with_red_boxing_gloves.png')\n",
    "image = cv2.imread('src/referee_gloves_detector/refeere_scaled.png')\n",
    "cv2.imshow(\"Original\", image)\n",
    " \n",
    "result = image.copy()\n",
    " \n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower1 = np.array([0, 100, 100])\n",
    "upper1 = np.array([5, 255, 255])\n",
    "\n",
    "lower2 = np.array([174,100,100])\n",
    "upper2 = np.array([179,255,255])\n",
    " \n",
    "lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "upper_mask = cv2.inRange(image, lower2, upper2)\n",
    " \n",
    "full_mask = lower_mask + upper_mask;\n",
    " \n",
    "result = cv2.bitwise_and(result, result, mask=full_mask)\n",
    "\n",
    "# #########################################\n",
    "# codice crop full height\n",
    "\n",
    "# creo una ROI a partire dalla maschera \n",
    "x,y,w,h = cv2.boundingRect(full_mask) \n",
    "rectangle_image = image.copy()\n",
    "extra_margin = 25 # margine extra a sinistra e destra\n",
    "w = w + extra_margin # sommo il margine extra alla larghezza della ROI\n",
    "y = 0 # no cropping su altezza\n",
    "h = image.shape[0] # no cropping su altezza\n",
    "# creo un rettangolo a partire dalla ROI\n",
    "cv2.rectangle(rectangle_image, (x-w,y), (x+(2*w),y+h), (255,0,0), 0)\n",
    "# mostro immagine con rettangolo # cv2.imshow('rectangled', rectangle_image)\n",
    "# croppo l'immagine usando la ROI\n",
    "cropped_rectangle = rectangle_image[y:y+h, (x-w):x+(2*w)]\n",
    "# riconverto l'immagine in colori umani\n",
    "cropped = cv2.cvtColor(cropped_rectangle, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "\n",
    "cv2.imshow('mask', full_mask)\n",
    "cv2.imshow('result', result)\n",
    "cv2.imshow('cropped', cropped)\n",
    "# ##########################################\n",
    " \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\example_shapes.png\"\n",
    "# uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\example_shapes_1.png\"\n",
    "# uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\example_shapes_2.png\"\n",
    "uri = \"src/referee_gloves_detector/bloisi_nao_red_hands.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apro la webcam e salvo al volo i frame e il timestamp\n",
    "\n",
    "webcam=cv2.VideoCapture(0) \n",
    "\n",
    "if not webcam.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura della webcam\")\n",
    "\n",
    "keypoints_vec = []\n",
    "timestamps = []\n",
    "resize = transforms.Resize([224, 224])  \n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=webcam.read()\n",
    "while ret:\n",
    "    \n",
    "    \n",
    "    istante_attuale = datetime.now()\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante) \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:,80:]\n",
    "    img = img[:,:-80]\n",
    "    \n",
    "\n",
    "    im_pil = Image.fromarray(img)\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        keypoints_vec.append(keypoints)\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        frame_modified = drawSkeleton(tensor[0], embedding[0])\n",
    "        #frame = drawKeypoints(tensor[0], keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame_modified)\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break         \n",
    "    ret, frame = webcam.read()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Dimensioni dell'array di frame:\", len(keypoints_vec))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7166fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam + cropping\n",
    "# Apro la webcam e salvo al volo i frame e il timestamp\n",
    "\n",
    "webcam=cv2.VideoCapture(0) \n",
    "\n",
    "if not webcam.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura della webcam\")\n",
    "\n",
    "keypoints_vec = []\n",
    "timestamps = []\n",
    "resize = transforms.Resize([224, 224])  \n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=webcam.read()\n",
    "while ret:\n",
    "    \n",
    "    \n",
    "    istante_attuale = datetime.now()\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante) \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower1 = np.array([0, 100, 100])\n",
    "upper1 = np.array([5, 255, 255])\n",
    "\n",
    "lower2 = np.array([174,100,100])\n",
    "upper2 = np.array([179,255,255])\n",
    " \n",
    "lower_mask = cv2.inRange(image, lower1, upper1)\n",
    "upper_mask = cv2.inRange(image, lower2, upper2)\n",
    " \n",
    "full_mask = lower_mask + upper_mask;\n",
    " \n",
    "result = cv2.bitwise_and(result, result, mask=full_mask)\n",
    "\n",
    "# #########################################\n",
    "# codice crop full height\n",
    "\n",
    "# creo una ROI a partire dalla maschera \n",
    "x,y,w,h = cv2.boundingRect(full_mask) \n",
    "rectangle_image = image.copy()\n",
    "extra_margin = 20 # margine extra a sinistra e destra\n",
    "w = w + extra_margin # sommo il margine extra alla larghezza della ROI\n",
    "y = 0 # no cropping su altezza\n",
    "h = image.shape[0] # no cropping su altezza\n",
    "# creo un rettangolo a partire dalla ROI\n",
    "cv2.rectangle(rectangle_image, (x,y), (x+w,y+h), (255,0,0), 0)\n",
    "# mostro immagine con rettangolo\n",
    "cv2.imshow('rectangled', rectangle_image)\n",
    "# croppo l'immagine usando la ROI\n",
    "cropped_rectangle = rectangle_image[y:y+h, x:x+w]\n",
    "# riconverto l'immagine in colori umani\n",
    "cropped = cv2.cvtColor(cropped_rectangle, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "\n",
    "    cv2.imshow('mask', full_mask)\n",
    "    cv2.imshow('cropped', cropped)\n",
    "    \n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:,80:]\n",
    "    img = img[:,:-80]\n",
    "    \n",
    "\n",
    "    im_pil = Image.fromarray(img)\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        keypoints_vec.append(keypoints)\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        frame_modified = drawSkeleton(tensor[0], embedding[0])\n",
    "        #frame = drawKeypoints(tensor[0], keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame_modified)\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break         \n",
    "    ret, frame = webcam.read()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Dimensioni dell'array di frame:\", len(keypoints_vec))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo solo i 9 keypoints scelti per ogni frame\n",
    "\n",
    "d = {'timestamp':[],'x': [], 'y': [], 'tag':[]}\n",
    "df_keypoints = pd.DataFrame(data=d)\n",
    "for timestamp, restricted_keypoints in zip(timestamps, keypoints_vec):\n",
    "    for i in range(len(restricted_keypoints[0])):\n",
    "        if not (restricted_keypoints[0][i]):\n",
    "            df_temp = pd.DataFrame([{'timestamp': '01/01/1970 01:00:00','x':np.nan, 'y':np.nan, 'tag':np.nan}])\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "        else:\n",
    "            df_temp = pd.DataFrame(restricted_keypoints[0][i])\n",
    "            df_temp['timestamp'] = timestamp\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "df_keypoints.to_csv(file_path_csv_keypoints_webcam, index=False)\n",
    "df_multiindex = df_keypoints.set_index(['timestamp'])\n",
    "display(df_multiindex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
