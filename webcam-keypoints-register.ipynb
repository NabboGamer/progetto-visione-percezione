{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(19, 'litepose-pose-estimation/src')\n",
    "sys.path.insert(20, 'src/referee_gloves_detector')\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import lp_config.lp_common_config as cc\n",
    "from lp_model.lp_litepose import LitePose\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, drawSkeleton\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import red_filtering, segmentation_and_cropping, equalizing, squaring\n",
    "import math\n",
    "from Homography import Homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f0f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggo il file di configurazione\n",
    "with open('config/config.json') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "# Ottengo i percorsi dei file\n",
    "file_path_big_arch = config_data['path_big_arch']\n",
    "file_path_csv_keypoints = config_data['path_csv_keypoints']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(file_path_big_arch, map_location=cc.config[\"device\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HOMOGRAPHY IMAGE\n",
    "\n",
    "uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\resources\\\\bloisi_nao_red_hands.png\"\n",
    "img = Image.open(uri).convert('RGB')\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "to_tensor = transforms.ToTensor()\n",
    "tensor = to_tensor(img)\n",
    "tensor = tensor.unsqueeze(0)\n",
    "output, keypoints = inference(model, tensor)\n",
    "embedding = assocEmbedding(keypoints)\n",
    "idx = 0\n",
    "img = drawKeypoints(tensor[idx], keypoints[idx])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "im_pil = Image.fromarray(img)\n",
    "im_pil.save('src/referee_gloves_detector/resources/src.jpg')\n",
    "keypoints_saver(keypoints)\n",
    "src = cv2.imread(\"src/referee_gloves_detector/resources/src.jpg\")\n",
    "dst = cv2.imread(\"src/referee_gloves_detector/resources/dst.jpg\")\n",
    "h = Homography(src,dst)\n",
    "h._from_detection()\n",
    "plan_view = cv2.warpPerspective(src, h.H, (dst.shape[1], dst.shape[0]))\n",
    "cv2.imshow(\"Reprojected view\", plan_view)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HOMOGRAPHY IMAGE AUTOMATICALLY\n",
    "\n",
    "uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\resources\\\\bloisi_nao_red_hands.png\"\n",
    "img = Image.open(uri).convert('RGB')\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "to_tensor = transforms.ToTensor()\n",
    "tensor = to_tensor(img)\n",
    "tensor = tensor.unsqueeze(0)\n",
    "output, keypoints = inference(model, tensor)\n",
    "restricted_keypoints = [[keypoints[0][0], keypoints[0][1], keypoints[0][6], keypoints[0][7], keypoints[0][8], keypoints[0][9], keypoints[0][10],keypoints[0][11],keypoints[0][12],keypoints[0][13]]]\n",
    "idx = 0\n",
    "img = drawKeypoints(tensor[idx], restricted_keypoints[idx])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "im_pil = Image.fromarray(img)\n",
    "im_pil.save('src/referee_gloves_detector/resources/src.jpg')\n",
    "keypoints_saver(restricted_keypoints)\n",
    "src = cv2.imread(\"src/referee_gloves_detector/resources/src.jpg\")\n",
    "dst = cv2.imread(\"src/referee_gloves_detector/resources/dst.jpg\")\n",
    "h = Homography(src,dst)\n",
    "punti3d = [[keypoints[0][0][0]['x'], keypoints[0][0][0]['y']], [keypoints[0][1][0]['x'], keypoints[0][1][0]['y']], [keypoints[0][6][0]['x'], keypoints[0][6][0]['y']], [keypoints[0][7][0]['x'], keypoints[0][7][0]['y']], [keypoints[0][8][0]['x'], keypoints[0][8][0]['y']], [keypoints[0][9][0]['x'], keypoints[0][9][0]['y']], [keypoints[0][10][0]['x'], keypoints[0][10][0]['y']], [keypoints[0][11][0]['x'], keypoints[0][11][0]['y']], [keypoints[0][12][0]['x'], keypoints[0][12][0]['y']],[keypoints[0][13][0]['x'], keypoints[0][13][0]['y']]]\n",
    "punti2d = [[263, 121], [74, 121], [212, 330], [116, 330], [229, 431], [101, 431], [228, 529], [100, 529], [166, 41], [166, 114]]\n",
    "corr = h.normalize_points(punti2d,punti3d)\n",
    "h._compute_view_based_homography(corr)\n",
    "plan_view = cv2.warpPerspective(src, h.H, (dst.shape[1], dst.shape[0]))\n",
    "cv2.imshow(\"Reprojected view\", plan_view)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# HOMOGRAPHY VIDEO\n",
    "\n",
    "uri = \"C:\\\\Users\\\\stolf\\\\dev\\\\Progetto Visione e Percezione\\\\src\\\\referee_gloves_detector\\\\resources\\\\referee_1.mp4\"\n",
    "cap = cv2.VideoCapture(uri)\n",
    "\n",
    "# Verifico se il video è stato aperto correttamente\n",
    "if not cap.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura del video\")\n",
    "\n",
    "resize = transforms.Resize([224, 224])\n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=cap.read()\n",
    "count = 0\n",
    "while ret:\n",
    "    #-----------------------------PREPROCESSING START HERE-----------------------------\n",
    "    #NORMALIZATION\n",
    "    normalized_image = cv2.normalize(frame, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    #EQUALIZATION\n",
    "    equalized_image = equalizing(normalized_image)\n",
    "    img = cv2.cvtColor(equalized_image, cv2.COLOR_BGR2RGB)\n",
    "    img = squaring(img)\n",
    "    #------------------------------PREPROCESSING END HERE------------------------------\n",
    "    try:\n",
    "        # Può dare problemi se gli arriva una immagine con una dimensione mancante,\n",
    "        # non ho capito il perchè (probabilmente è causata dall'algoritmo di cropping)\n",
    "        # ma questo può succedere\n",
    "        im_pil = Image.fromarray(img)\n",
    "    except:\n",
    "        print(\"Shape dell'immagine che farebbe crashare il processo: \" + str(img.shape))\n",
    "        pass\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "\n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        restricted_keypoints = [[keypoints[0][0], keypoints[0][1], keypoints[0][6], keypoints[0][7], keypoints[0][8], keypoints[0][9], keypoints[0][10],keypoints[0][11],keypoints[0][12],keypoints[0][13]]]\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        #frame = drawSkeleton(tensor[0], embedding[0])\n",
    "        frame = drawKeypoints(tensor[0], restricted_keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame)\n",
    "\n",
    "        #-----------------------------HOMOGRAPHY START HERE-----------------------------\n",
    "        image_pil = Image.fromarray(frame, 'RGB')\n",
    "        image_pil.save('src/referee_gloves_detector/resources/src.jpg')\n",
    "        src = frame\n",
    "        dst = cv2.imread(\"src/referee_gloves_detector/resources/dst.jpg\")\n",
    "        h = Homography(src,dst)\n",
    "        punti2d = [[263, 121], [74, 121], [212, 330], [116, 330], [229, 431], [101, 431], [228, 529], [100, 529], [166, 41], [166, 114]]\n",
    "        punti3d = []\n",
    "        index_list = [0, 1, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "        count = 0\n",
    "        index_to_remove = []\n",
    "        for i in index_list:\n",
    "            try:\n",
    "                punti3d.append([keypoints[0][i][0]['x'], keypoints[0][i][0]['y']])\n",
    "            except:\n",
    "                index_to_remove.append(count)\n",
    "            finally:\n",
    "                count = count + 1\n",
    "        for index in sorted(index_to_remove, reverse=True):\n",
    "            del punti2d[index]\n",
    "        corr = h.normalize_points(punti2d,punti3d)\n",
    "        h._compute_view_based_homography(corr)\n",
    "        plan_view = cv2.warpPerspective(src, h.H, (dst.shape[1], dst.shape[0]))\n",
    "        cv2.imshow(\"Pose estimation homography\", plan_view)\n",
    "        #------------------------------HOMOGRAPHY END HERE------------------------------\n",
    "\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apro la webcam e salvo al volo i frame e il timestamp\n",
    "\n",
    "webcam=cv2.VideoCapture(0)\n",
    "\n",
    "if not webcam.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura della webcam\")\n",
    "\n",
    "keypoints_vec = []\n",
    "timestamps = []\n",
    "resize = transforms.Resize([224, 224])\n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=webcam.read()\n",
    "while ret:\n",
    "\n",
    "\n",
    "    istante_attuale = datetime.now()\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante)\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    #-----------------------------PREPROCESSING START HERE-----------------------------\n",
    "    #RED FILTERING\n",
    "    full_mask = red_filtering(frame)\n",
    "    #SEGMENTATION E CROPPING\n",
    "    cropped_image = segmentation_and_cropping(frame, full_mask)\n",
    "    #NORMALIZATION\n",
    "    normalized_image = cv2.normalize(cropped_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    #EQUALIZATION\n",
    "    equalized_image = equalizing(normalized_image)\n",
    "    #------------------------------PREPROCESSING END HERE------------------------------\n",
    "    img = cv2.cvtColor(equalized_image, cv2.COLOR_BGR2RGB)\n",
    "    img = squaring(img)\n",
    "\n",
    "    try:\n",
    "        # Può dare problemi se gli arriva una immagine con una dimensione mancante,\n",
    "        # non ho capito il perchè (probabilmente è causata dall'algoritmo di cropping)\n",
    "        # ma questo può succedere\n",
    "        im_pil = Image.fromarray(img)\n",
    "    except:\n",
    "        print(\"Shape dell'immagine che farebbe crashare il processo: \" + str(img.shape))\n",
    "        pass\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "\n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        keypoints_vec.append(keypoints)\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        frame_modified = drawSkeleton(tensor[0], embedding[0])\n",
    "        #frame = drawKeypoints(tensor[0], keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame_modified)\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break\n",
    "    ret, frame = webcam.read()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Dimensioni dell'array di frame:\", len(keypoints_vec))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbbadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
