{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ce0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(19, 'litepose-pose-estimation/src')\n",
    "sys.path.insert(20, 'src/referee_gloves_detector')\n",
    "import json\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import lp_config.lp_common_config as cc\n",
    "from lp_model.lp_litepose import LitePose\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, drawSkeleton\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from preprocessing import red_filtering, segmentation_and_cropping, equalizing, squaring\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07f0f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggo il file di configurazione\n",
    "with open('config/config.json') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "# Ottengo i percorsi dei file\n",
    "file_path_big_arch = config_data['path_big_arch']\n",
    "file_path_csv_keypoints_webcam = config_data['path_csv_keypoints_webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3e6c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(file_path_big_arch, map_location=cc.config[\"device\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba1f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uri = \"src/referee_gloves_detector/resources/example_shapes.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/example_shapes_1.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/example_shapes_2.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/bloisi_nao_red_hands.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/refeere_scaled.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/person_with_red_boxing_gloves.png\"\n",
    "#uri = \"src/referee_gloves_detector/resources/refeere_scaled_v2.png\"\n",
    "uri = \"src/referee_gloves_detector/resources/bloisi_nao_red_hands_v2.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c2fffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED FILTERING\n",
    "\n",
    "image = cv2.imread(uri)\n",
    "full_mask = red_filtering(image)\n",
    "cv2.imshow('mask', full_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2891b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGMENTATION E CROPPING\n",
    "\n",
    "cropped_image = segmentation_and_cropping(image, full_mask)\n",
    "cv2.imshow('cropped', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6b1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "\n",
    "normalized_image = cv2.normalize(cropped_image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "cv2.imshow('normalized', normalized_image)\n",
    "cv2.imshow('cropped', cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51b0ef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EQUALIZATION\n",
    "\n",
    "equalized_image = equalizing(cropped_image)\n",
    "cv2.imshow('cropped', cropped_image)\n",
    "cv2.imshow('equalized', equalized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1492b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 156, 3)\n",
      "(224, 156, 3)\n"
     ]
    }
   ],
   "source": [
    "# SQUARING IMAGE\n",
    "\n",
    "image = cv2.imread(uri)\n",
    "print(image.shape)\n",
    "squared_image = squaring(image)\n",
    "print(squared_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b987acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensioni dell'array di frame: 29\n",
      "Dimensioni dell'array di timestamp: 29\n"
     ]
    }
   ],
   "source": [
    "# Apro la webcam e salvo al volo i frame e il timestamp\n",
    "\n",
    "webcam=cv2.VideoCapture(0) \n",
    "\n",
    "if not webcam.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura della webcam\")\n",
    "\n",
    "keypoints_vec = []\n",
    "timestamps = []\n",
    "resize = transforms.Resize([224, 224])  \n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=webcam.read()\n",
    "while ret:\n",
    "    \n",
    "    \n",
    "    istante_attuale = datetime.now()\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante) \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    #-----------------------------PREPROCESSING START HERE-----------------------------\n",
    "    #RED FILTERING\n",
    "    full_mask = red_filtering(frame)\n",
    "    #SEGMENTATION E CROPPING\n",
    "    cropped_image = segmentation_and_cropping(frame, full_mask)\n",
    "    #NORMALIZATION\n",
    "    normalized_image = cv2.normalize(cropped_image, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "    #EQUALIZATION\n",
    "    equalized_image = equalizing(normalized_image)\n",
    "    #------------------------------PREPROCESSING END HERE------------------------------\n",
    "    img = cv2.cvtColor(equalized_image, cv2.COLOR_BGR2RGB)\n",
    "    img = squaring(img)\n",
    "    \n",
    "    try:\n",
    "        # Può dare problemi se gli arriva una immagine con una dimensione mancante,\n",
    "        # non ho capito il perchè (anche perchè è una condizione difficilmente riproducibile) \n",
    "        # ma questo può succedere\n",
    "        im_pil = Image.fromarray(img)\n",
    "    except:\n",
    "        print(\"Shape dell'immagine che fa crashare il processo: \" + str(img.shape))\n",
    "        pass\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    \n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        keypoints_vec.append(keypoints)\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        frame_modified = drawSkeleton(tensor[0], embedding[0])\n",
    "        #frame = drawKeypoints(tensor[0], keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame_modified)\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break         \n",
    "    ret, frame = webcam.read()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Dimensioni dell'array di frame:\", len(keypoints_vec))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo solo i 9 keypoints scelti per ogni frame\n",
    "\n",
    "d = {'timestamp':[],'x': [], 'y': [], 'tag':[]}\n",
    "df_keypoints = pd.DataFrame(data=d)\n",
    "for timestamp, restricted_keypoints in zip(timestamps, keypoints_vec):\n",
    "    for i in range(len(restricted_keypoints[0])):\n",
    "        if not (restricted_keypoints[0][i]):\n",
    "            df_temp = pd.DataFrame([{'timestamp': '01/01/1970 01:00:00','x':np.nan, 'y':np.nan, 'tag':np.nan}])\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "        else:\n",
    "            df_temp = pd.DataFrame(restricted_keypoints[0][i])\n",
    "            df_temp['timestamp'] = timestamp\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "df_keypoints.to_csv(file_path_csv_keypoints_webcam, index=False)\n",
    "df_multiindex = df_keypoints.set_index(['timestamp'])\n",
    "display(df_multiindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbbadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
