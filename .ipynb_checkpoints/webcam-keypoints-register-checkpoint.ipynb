{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ce0c0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.insert(19, 'litepose-pose-estimation/src')\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import lp_config.lp_common_config as cc\n",
    "from lp_model.lp_litepose import LitePose\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, drawSkeleton\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imutils\n",
    "sys.path.insert(20, 'src/referee_gloves_detector')\n",
    "from color_labeler import ColorLabeler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07f0f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggo il file di configurazione\n",
    "with open('config/config.json') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "# Ottengo i percorsi dei file\n",
    "file_path_big_arch = config_data['path_big_arch']\n",
    "file_path_csv_keypoints_webcam = config_data['path_csv_keypoints_webcam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3e6c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(file_path_big_arch, map_location=cc.config[\"device\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7078a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refeere_detector(image):\n",
    "    resized = imutils.resize(image, width=300)\n",
    "    ratio = image.shape[0] / float(resized.shape[0])\n",
    "    # aggiunge del leggero Blur all'immagine, dopodich√© la converte in Scala di grigi e spazio di colori L*a*b* \n",
    "    blurred = cv2.GaussianBlur(resized, (5, 5), 0)\n",
    "    # Se OpenCv ti mostra in maniera errata le label cambia ls costante COLOR_RGB2GRAY a COLOR_BGR2GRAY\n",
    "    gray = cv2.cvtColor(blurred, cv2.COLOR_RGB2GRAY)\n",
    "    lab = cv2.cvtColor(blurred, cv2.COLOR_RGB2LAB) \n",
    "    thresh = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    # trova i contorni nell'immagine con soglia\n",
    "    # controllo se sto usando OpenCV 2.X o OpenCV 4\n",
    "    if imutils.is_cv2() or imutils.is_cv4():\n",
    "        (cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # controllo se sto usando OpenCV 3\n",
    "    elif imutils.is_cv3():\n",
    "        (_, cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # inizializza il rilevatore di forma e l'etichettatore di colore \n",
    "    # sd = ShapeDetector()\n",
    "    cl = ColorLabeler()\n",
    "\n",
    "    # itera sui contorni\n",
    "    for c in cnts:\n",
    "        # calcola il centro del contorno\n",
    "        M = cv2.moments(c)\n",
    "        cX = int((M[\"m10\"] / M[\"m00\"]) * ratio)\n",
    "        cY = int((M[\"m01\"] / M[\"m00\"]) * ratio)\n",
    "        # rileva la forma del contorno ed etichetta il colore\n",
    "        # shape = sd.detect(c)\n",
    "        color = cl.label(lab, c)\n",
    "        print(color)\n",
    "        if(color == \"red\"):\n",
    "            # moltiplica le coordinate-(x,y) del contorno per il rapporto d'aspetto ridimensionato,\n",
    "            # poi disegna i contorni e il nome della forma assieme al colore etichettato sull'immagine \n",
    "            c = c.astype(\"float\")\n",
    "            c *= ratio\n",
    "            c = c.astype(\"int\")\n",
    "            text = \"{} {}\".format(color, \"glove\")\n",
    "            cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, text, (cX, cY),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6364b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apro la webcam e salvo al volo i frame e il timestamp\n",
    "\n",
    "webcam=cv2.VideoCapture(0) \n",
    "\n",
    "if not webcam.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura della webcam\")\n",
    "\n",
    "keypoints_vec = []\n",
    "timestamps = []\n",
    "resize = transforms.Resize([224, 224])  \n",
    "to_tensor = transforms.ToTensor()\n",
    "ret,frame=webcam.read()\n",
    "while ret:\n",
    "    \n",
    "    \n",
    "    istante_attuale = datetime.now()\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante) \n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:,80:]\n",
    "    img = img[:,:-80]\n",
    "    \n",
    "\n",
    "    im_pil = Image.fromarray(img)\n",
    "    frame = resize(im_pil)\n",
    "    tensor = to_tensor(frame)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "    if ret==True:\n",
    "        output, keypoints = inference(model, tensor)\n",
    "        keypoints_vec.append(keypoints)\n",
    "        embedding = assocEmbedding(keypoints)\n",
    "        frame_modified = drawSkeleton(tensor[0], embedding[0])\n",
    "        #frame = drawKeypoints(tensor[0], keypoints[0])\n",
    "        cv2.imshow(\"Pose estimation\", frame_modified)\n",
    "        key=cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break         \n",
    "    ret, frame = webcam.read()\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Dimensioni dell'array di frame:\", len(keypoints_vec))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo solo i 9 keypoints scelti per ogni frame\n",
    "\n",
    "d = {'timestamp':[],'x': [], 'y': [], 'tag':[]}\n",
    "df_keypoints = pd.DataFrame(data=d)\n",
    "for timestamp, restricted_keypoints in zip(timestamps, keypoints_vec):\n",
    "    for i in range(len(restricted_keypoints[0])):\n",
    "        if not (restricted_keypoints[0][i]):\n",
    "            df_temp = pd.DataFrame([{'timestamp': '01/01/1970 01:00:00','x':np.nan, 'y':np.nan, 'tag':np.nan}])\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "        else:\n",
    "            df_temp = pd.DataFrame(restricted_keypoints[0][i])\n",
    "            df_temp['timestamp'] = timestamp\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "df_keypoints.to_csv(file_path_csv_keypoints_webcam, index=False)\n",
    "df_multiindex = df_keypoints.set_index(['timestamp'])\n",
    "display(df_multiindex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
