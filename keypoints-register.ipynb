{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b839e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "sys.path.insert(19, 'litepose-pose-estimation/src')\n",
    "\n",
    "from lp_coco_utils.lp_getDataset import getDatasetProcessed\n",
    "from lp_training.lp_trainer import train\n",
    "from lp_model.lp_litepose import LitePose\n",
    "from lp_inference.lp_inference import inference, assocEmbedding\n",
    "from lp_utils.lp_image_processing import drawHeatmap, drawKeypoints, drawSkeleton\n",
    "from lp_testing.lp_evaluate import evaluateModel\n",
    "\n",
    "import lp_config.lp_common_config as cc\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "from thop import profile\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.request import urlopen\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pytube import YouTube\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1679d8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggo il file di configurazione\n",
    "with open('config/config.json') as f:\n",
    "    config_data = json.load(f)\n",
    "\n",
    "# Ottengo i percorsi dei file\n",
    "file_path_big_arch = config_data['path_big_arch']\n",
    "file_path_csv_keypoints = config_data['path_csv_keypoints']\n",
    "file_path_video = config_data['path_video']\n",
    "file_path_csv_keypoints_video = config_data['path_csv_keypoints_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carico il modello già addestrato\n",
    "\n",
    "model = LitePose().to(cc.config[\"device\"])\n",
    "model.load_state_dict(torch.load(file_path_big_arch, map_location=cc.config[\"device\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carico una immagine statica da url\n",
    "\n",
    "#url = 'https://web.unibas.it/bloisi/assets/images/bloisi_nao.jpg'\n",
    "#url = 'https://previews.123rf.com/images/mimagephotography/mimagephotography1411/mimagephotography141100024/33214727-full-body-portrait-of-a-handsome-young-african-american-man-smiling-on-isolated-white-background.jpg'\n",
    "\n",
    "#uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (113).png\"\n",
    "#uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (114).png\"\n",
    "#uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (115).png\"\n",
    "#uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (116).png\"\n",
    "#uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (117).png\"\n",
    "uri = \"C:\\\\Users\\\\stolf\\\\Downloads\\\\Screenshot (118).png\"\n",
    "\n",
    "#img = Image.open(urlopen(url)).convert('RGB')\n",
    "img = Image.open(uri).convert('RGB')\n",
    "plt.grid(False)\n",
    "_= plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dab6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatto l'immagine alle dimensioni di un tensore PyTorch \n",
    "\n",
    "# Ridimensiono l'immagine\n",
    "resize = transforms.Resize([224, 224])\n",
    "img = resize(img)\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Trasformo l'immagine in un tensore\n",
    "tensor = to_tensor(img)\n",
    "# torch.Size([3, 224, 224])\n",
    "\n",
    "# Aggiungo un'altra dimensione per far corrispondere la shape del tensore alla shape (NCHW) di un tensore PyTorch\n",
    "tensor = tensor.unsqueeze(0)\n",
    "# torch.Size([1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f030518b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferisco i Keypoints dall'immagine\n",
    "\n",
    "output, keypoints = inference(model, tensor)\n",
    "embedding = assocEmbedding(keypoints)\n",
    "restricted_keypoints = [[keypoints[0][0], keypoints[0][1], keypoints[0][2], keypoints[0][3], keypoints[0][4], keypoints[0][5], keypoints[0][6],keypoints[0][7],keypoints[0][13]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f2dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disegno i keypoints inferiti sull'immagine\n",
    "\n",
    "idx = 0\n",
    "img = drawKeypoints(tensor[idx], restricted_keypoints[idx])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "im_pil = Image.fromarray(img)\n",
    "plt.grid(False)\n",
    "_= plt.imshow(im_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ceeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disegno lo skeleton a partire dai keypoints\n",
    "\n",
    "idx = 0\n",
    "img = drawSkeleton(tensor[idx], embedding[idx])\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "im_pil = Image.fromarray(img)\n",
    "plt.grid(False)\n",
    "_= plt.imshow(im_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37637e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo solo i 9 keypoints scelti\n",
    "\n",
    "#display(restricted_keypoints)\n",
    "d = {'x': [], 'y': [], 'tag':[]}\n",
    "df_keypoints = pd.DataFrame(data=d)\n",
    "for i in range(len(restricted_keypoints[0])):\n",
    "    if not (restricted_keypoints[0][i]):\n",
    "        df_temp = pd.DataFrame([{'x':np.nan, 'y':np.nan, 'tag':np.nan}])\n",
    "        df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "    else:\n",
    "        df_temp = pd.DataFrame(restricted_keypoints[0][i])\n",
    "        df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "df_keypoints.reset_index(drop=True, inplace=True)\n",
    "df_keypoints.to_csv(file_path_csv_keypoints, index=False)\n",
    "df_keypoints.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carico una video da url\n",
    "\n",
    "def video_downloader(link):\n",
    "    youtubeObject = YouTube(link)\n",
    "    youtubeObject = youtubeObject.streams.get_by_resolution(\"360p\")\n",
    "    try:\n",
    "        youtubeObject.download(filename='referee.mp4')\n",
    "    except:\n",
    "        raise Exception(\"Si è verificato un errore nel download del video\")\n",
    "    print(\"Download completato correttamente\")\n",
    "\n",
    "\n",
    "url = 'https://youtu.be/bBuDwm6JrZw'\n",
    "video_downloader(url)\n",
    "\n",
    "# Apro il file video\n",
    "cap = cv2.VideoCapture(file_path_video)\n",
    "\n",
    "# Verifico se il video è stato aperto correttamente\n",
    "if not cap.isOpened():\n",
    "    raise Exception(\"Errore nell'apertura del video\")\n",
    "\n",
    "frames = []\n",
    "timestamps = []\n",
    "ret, frame = cap.read()\n",
    "count = 0\n",
    "while ret:\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    im_pil = Image.fromarray(img)\n",
    "    frames.append(im_pil)\n",
    "    # Ottengo l'istante attuale\n",
    "    istante_attuale = datetime.now()\n",
    "    # Converto l'istante in una stringa nel formato desiderato\n",
    "    stringa_istante = istante_attuale.strftime(\"%d/%m/%Y %H:%M:%S.%f\")\n",
    "    timestamps.append(stringa_istante)\n",
    "    # Leggo il successivo frame\n",
    "    ret, frame = cap.read()\n",
    "    count += 1\n",
    "    # Imposto il frame successivo da leggere dopo 15 ms\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, count * 15)\n",
    "\n",
    "# Chiudo il file video\n",
    "cap.release()\n",
    "\n",
    "# Stampa le dimensioni dell'array\n",
    "print(\"Dimensioni dell'array di frame:\", len(frames))\n",
    "print(\"Dimensioni dell'array di timestamp:\", len(timestamps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diminuisco il numero di frame per alleggerire il carico computazionale\n",
    "\n",
    "frames = frames[0:500]\n",
    "timestamps = timestamps[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051ec4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adatto le immagini alle dimensioni dei tensori PyTorch \n",
    "\n",
    "display(len(frames)) # numero di frames (immagini)\n",
    "\n",
    "# Adatto i frames alle dimensioni di un tensore PyTorch \n",
    "resize = transforms.Resize([224, 224])  \n",
    "to_tensor = transforms.ToTensor() \n",
    "tensors = [] # Creo la lista di tensori\n",
    "for frame in frames:\n",
    "    frame = resize(frame) # Ridimensiono le dimensioni dei frames\n",
    "    tensor = to_tensor(frame) # Trasformo il frame in tensore\n",
    "    tensor = tensor.unsqueeze(0) # Aggiungo un'altra dimensione per far corrispondere la shape del tensore alla shape (NCHW) di un tensore PyTorch\n",
    "    tensors.append(tensor) # Aggiungo il frame convertito in tensore alla lista di tensori\n",
    "\n",
    "display(len(tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferisco i Keypoints dai frame\n",
    "\n",
    "restricted_keypoints_vec = []\n",
    "embedding_vec = []\n",
    "for tensor in tqdm(tensors):\n",
    "    output, keypoints = inference(model, tensor)\n",
    "    embedding = assocEmbedding(keypoints)\n",
    "    restricted_keypoints = [[keypoints[0][0], keypoints[0][1], keypoints[0][2], keypoints[0][3], keypoints[0][4], keypoints[0][5], keypoints[0][6],keypoints[0][7],keypoints[0][13]]]    \n",
    "    restricted_keypoints_vec.append(restricted_keypoints)\n",
    "    embedding_vec.append(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0870c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Disegno i keypoints inferiti sui frame\n",
    "\n",
    "idx = 0\n",
    "for tensor, restricted_keypoints in zip(tensors, restricted_keypoints_vec):\n",
    "    frame = drawKeypoints(tensor[idx], restricted_keypoints[idx])\n",
    "    cv2.imshow(\"Image Keypoints\", frame)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020081af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disegno gli skeleton a partire dai keypoints\n",
    "\n",
    "idx = 0\n",
    "for tensor, embedding in zip(tensors, embedding_vec):\n",
    "    frame = drawSkeleton(tensor[idx], embedding[idx])\n",
    "    cv2.imshow(\"Image Keypoints\", frame)\n",
    "    cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4278e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvo solo i 9 keypoints scelti per ogni frame\n",
    "\n",
    "d = {'timestamp':[],'x': [], 'y': [], 'tag':[]}\n",
    "df_keypoints = pd.DataFrame(data=d)\n",
    "for timestamp, restricted_keypoints in zip(timestamps, restricted_keypoints_vec):\n",
    "    for i in range(len(restricted_keypoints[0])):\n",
    "        if not (restricted_keypoints[0][i]):\n",
    "            df_temp = pd.DataFrame([{'timestamp': '01/01/1970 01:00:00','x':np.nan, 'y':np.nan, 'tag':np.nan}])\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "        else:\n",
    "            df_temp = pd.DataFrame(restricted_keypoints[0][i])\n",
    "            df_temp['timestamp'] = timestamp\n",
    "            df_keypoints = pd.concat([df_keypoints, df_temp])\n",
    "df_keypoints.to_csv(file_path_csv_keypoints_video, index=False)\n",
    "df_multiindex = df_keypoints.set_index(['timestamp'])\n",
    "display(df_multiindex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
